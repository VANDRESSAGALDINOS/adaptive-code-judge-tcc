# Real-World Experiments - Language Bias Detection and Correction

## **Contexto e PropÃ³sito**

### **Objetivo Principal**
Esta pasta contÃ©m experimentos reais para demonstrar, quantificar e corrigir injustiÃ§as sistemÃ¡ticas entre linguagens de programaÃ§Ã£o (C++ vs Python) em plataformas de juÃ­zes online, usando problemas reais e metodologia cientÃ­fica rigorosa.

### **Diferencial vs Experimentos TeÃ³ricos**
- **`experiments/`**: Experimentos teÃ³ricos com 6 classes de complexidade (O(1) atÃ© O(2â¿))
- **`experiments_realworld/`**: Experimentos com problemas reais de plataformas (CSES, AtCoder) 

## **Estrutura Organizacional**

```
experiments_realworld/
â”œâ”€â”€ README.md                    # Este arquivo - contexto geral
â”œâ”€â”€ graphs/                      # Problemas de grafos (alta penalizaÃ§Ã£o Python)
â”‚   â””â”€â”€ problem01/              # CSES 1672 - Shortest Routes II (PRINCIPAL)
â”œâ”€â”€ dp/                         # Dynamic Programming (mÃ©dia penalizaÃ§Ã£o)
â”œâ”€â”€ backtracking/               # Backtracking (alta penalizaÃ§Ã£o)
â””â”€â”€ recursion/                  # RecursÃ£o profunda (alta penalizaÃ§Ã£o)
```

## **Problem01 - Experimento Principal (COMPLETO)**

### **Status: Pronto para ImplementaÃ§Ã£o de Benchmark**

O `graphs/problem01/` contÃ©m o experimento principal completamente preparado:

#### **ConteÃºdo DisponÃ­vel:**
```
graphs/problem01/
â”œâ”€â”€ problem_description.md       # DescriÃ§Ã£o acadÃªmica completa
â”œâ”€â”€ experiment_plan.md          # PLANO DE AÃ‡ÃƒO DETALHADO
â”œâ”€â”€ formal_proof.md             # Prova matemÃ¡tica de equivalÃªncia
â”œâ”€â”€ experiment_metadata.json    # Metadados estruturados
â”œâ”€â”€ solutions/                  # ImplementaÃ§Ãµes eficientes
â”‚   â”œâ”€â”€ solution.cpp            # C++ otimizado (CSES ACCEPTED)
â”‚   â””â”€â”€ solution.py             # Python equivalente
â”œâ”€â”€ tests_cses/                 # 16 casos de teste oficiais
â”‚   â”œâ”€â”€ 1.in + 1.out           # Casos pequenos (controle)
â”‚   â”œâ”€â”€ 8.in + 8.out           # Caso principal (calibraÃ§Ã£o) 
â”‚   â”œâ”€â”€ 12.in + 12.out         # Alta densidade
â”‚   â”œâ”€â”€ 15.in + 15.out         # MÃ¡xima densidade
â”‚   â””â”€â”€ ...                    # Todos os 16 casos
â””â”€â”€ slow_validation/            # ValidaÃ§Ã£o de seletividade
    â”œâ”€â”€ slow_solutions_description.md  # Metodologia soluÃ§Ãµes lentas
    â”œâ”€â”€ tle_validation_report.md       # Template de resultados
    â””â”€â”€ solutions_slow/                # SoluÃ§Ãµes O(nâ´) 
        â”œâ”€â”€ slow_solution.cpp          # C++ deliberadamente lento
        â””â”€â”€ slow_solution.py           # Python deliberadamente lento
```

#### **ValidaÃ§Ã£o Externa JÃ¡ Realizada:**
```
CSES Submissions Documentadas:
âœ… C++ Eficiente: https://cses.fi/problemset/result/14297533/ (ACCEPTED)
âœ… C++ Lento: https://cses.fi/problemset/result/14298232/ (TLE - seletividade)
âœ… Python Lento: https://cses.fi/problemset/result/14298238/ (TLE - seletividade)

EvidÃªncia de InjustiÃ§a: Python eficiente falha em 9/16 casos (56%) no CSES
```

## **Plano de AÃ§Ã£o - LocalizaÃ§Ã£o**

### **Documento Principal: `graphs/problem01/experiment_plan.md`**

O plano de aÃ§Ã£o completo estÃ¡ em **`experiments_realworld/graphs/problem01/experiment_plan.md`** contendo:

1. **Metodologia detalhada** (5 fases experimentais)
2. **Protocolo de execuÃ§Ã£o** (Docker, repetiÃ§Ãµes, mÃ©tricas)
3. **EstratÃ©gia otimizada** (6 casos estratÃ©gicos vs 16 totais)
4. **CritÃ©rios de sucesso** (quantitativos e explÃ­citos)
5. **Timeline realista** (5 dias â†’ implementaÃ§Ã£o imediata)

### **Resumo Executivo do Plano:**

#### **Fase 1: CalibraÃ§Ã£o (Test Case #8)**
```bash
Objetivo: Calcular fator de ajuste Python/C++
MÃ©todo: 15 repetiÃ§Ãµes no caso crÃ­tico maior
Tempo: ~1 minuto de execuÃ§Ã£o
Output: adjustment_factor (esperado: ~2.8x)
```

#### **Fase 2: ValidaÃ§Ã£o (6 casos estratÃ©gicos)**
```bash
Casos CrÃ­ticos: #8, #12, #15 (TLE em Python tradicional)
Casos Controle: #1, #13, #16 (ACCEPTED em Python tradicional)
MÃ©todo: 5 repetiÃ§Ãµes Ã— 4 condiÃ§Ãµes (tradicional vs adaptativo)
Tempo: ~2 minutos de execuÃ§Ã£o
```

#### **Fase 3: AnÃ¡lise EstatÃ­stica**
```bash
MÃ©tricas Principais:
- tle_reduction_absolute (esperado: 50+ pontos percentuais)
- cases_rescued (esperado: 3 casos crÃ­ticos)
- adjustment_factor (esperado: 2.5-3.0x)
```

## **O Que Implementar No Mac**

### **PrÃ³ximos Passos EspecÃ­ficos:**

#### **1. Script de Benchmark Principal:**
```bash
# Criar: experiments_realworld/graphs/problem01/run_benchmark.py
# FunÃ§Ã£o: Executar protocolo experimental automatizado
# Base: experiment_plan.md seÃ§Ãµes 4.2-4.4
```

#### **2. Ambiente Docker Setup:**
```bash
# Setup de containers isolados para C++ e Python
# CompilaÃ§Ã£o padronizada e execuÃ§Ã£o controlada
# Base: experiment_plan.md seÃ§Ã£o 4.1
```

#### **3. Script de AnÃ¡lise EstatÃ­stica:**
```bash
# Criar: experiments_realworld/graphs/problem01/analyze_results.py
# FunÃ§Ã£o: Processar tempos, calcular mÃ©tricas, gerar relatÃ³rios
# Base: experiment_plan.md seÃ§Ã£o 5
```

#### **4. ValidaÃ§Ã£o de Seletividade:**
```bash
# Executar soluÃ§Ãµes lentas localmente
# Confirmar TLE em ambas linguagens (mesmo com ajuste)
# Base: slow_validation/slow_solutions_description.md
```

### **Arquivos de SaÃ­da Esperados:**
```
results/
â”œâ”€â”€ calibration_results.json       # Dados de calibraÃ§Ã£o
â”œâ”€â”€ validation_results.json        # Dados de validaÃ§Ã£o sistÃªmica  
â”œâ”€â”€ statistical_analysis.json      # MÃ©tricas calculadas
â”œâ”€â”€ benchmark_summary.md           # RelatÃ³rio executivo
â””â”€â”€ execution_logs/                # Logs detalhados
```

## **Metodologia CientÃ­fica Aplicada**

### **Framework Estabelecido:**
1. **EquivalÃªncia Formal** âœ… (prova matemÃ¡tica completa)
2. **ValidaÃ§Ã£o Externa** âœ… (submissÃµes CSES documentadas)
3. **Benchmark Controlado** â³ (implementaÃ§Ã£o pendente)
4. **AnÃ¡lise EstatÃ­stica** â³ (implementaÃ§Ã£o pendente)
5. **Seletividade Validation** â³ (implementaÃ§Ã£o pendente)

### **Rigor Experimental:**
- Ambiente Docker isolado
- Test cases oficiais (16 casos CSES)
- RepetiÃ§Ãµes estatisticamente adequadas (15+5)
- MÃ©tricas zero-division-safe
- ValidaÃ§Ã£o cross-platform

## **Valor Para TCC**

### **ContribuiÃ§Ãµes Esperadas:**
1. **InjustiÃ§a Quantificada**: Primeira mediÃ§Ã£o sistemÃ¡tica (56% casos Python TLE)
2. **SoluÃ§Ã£o Validada**: Sistema adaptativo com fator empÃ­rico (2.8x)
3. **Seletividade Preservada**: Anti-gaming via soluÃ§Ãµes ineficientes
4. **Framework ReplicÃ¡vel**: Metodologia para outras linguagens/plataformas

### **Timeline de ExecuÃ§Ã£o:**
```
ImplementaÃ§Ã£o: 4-6 horas (scripts + Docker setup)
ExecuÃ§Ã£o: 5 minutos (benchmark automatizado)
AnÃ¡lise: 1-2 horas (estatÃ­sticas + relatÃ³rios)
Total: 1 dia de trabalho concentrado
```

## **Status dos Outros Problemas**

### **Graphs/DP/Backtracking/Recursion Problem02/03:**
```
Status: Estrutura criada, mas placeholders vazios
Prioridade: Baixa (problem01 Ã© suficiente para TCC)
Uso Futuro: ExpansÃ£o opcional para validaÃ§Ã£o adicional
```

### **RecomendaÃ§Ã£o:**
**Focar 100% no graphs/problem01 - Ã© completo e suficiente para demonstrar toda a metodologia e obter resultados de alto impacto para o TCC.**

---

## **Resumo para ContinuaÃ§Ã£o**

### **VocÃª tem:**
âœ… Problema real validado externamente  
âœ… Metodologia cientÃ­fica rigorosa  
âœ… DocumentaÃ§Ã£o acadÃªmica completa  
âœ… Plano de execuÃ§Ã£o otimizado  
âœ… Estrutura experimental organizada  

### **VocÃª precisa implementar:**
â³ Scripts de benchmark automatizado  
â³ AnÃ¡lise estatÃ­stica dos resultados  
â³ RelatÃ³rios finais para TCC  

### **LocalizaÃ§Ã£o do Plano:**
ğŸ“ **`experiments_realworld/graphs/problem01/experiment_plan.md`**

**Este Ã© o documento principal para implementaÃ§Ã£o - contÃ©m todos os detalhes tÃ©cnicos, comandos, protocolos e especificaÃ§Ãµes necessÃ¡rias.**
